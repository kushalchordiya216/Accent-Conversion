{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from fastdtw import fastdtw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from librosa import display\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw(df_in,df_out):\n",
    "    in_data = np.zeros((25,0))\n",
    "    out_data = np.zeros((25,0))\n",
    "    distance, path = fastdtw(df_in.T,df_out.T)\n",
    "    for i in range(1,len(path)):\n",
    "        index_in, index_out = path[i]\n",
    "        a = df_in[:,index_in:index_in+1]\n",
    "        b = df_out[:,index_out:index_out+1]\n",
    "        in_data = np.append(in_data, a, axis = 1)\n",
    "        out_data = np.append(out_data, b, axis = 1)\n",
    "    return (out_data, in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name_indata,name_outdata):\n",
    "    in_data = np.zeros((25,0))\n",
    "    out_data = np.zeros((25,0))\n",
    "    for i in range(1,540):\n",
    "        df_in = pd.read_csv('cmu_us_'+ name_indata +'_arctic/wav/mfcc/arctic_b00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_in = df_in.values\n",
    "        df_out = pd.read_csv('cmu_us_'+ name_outdata +'_arctic/wav/mfcc/arctic_b00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_out = df_out.values\n",
    "        df_in,df_out = dtw(df_in,df_out)\n",
    "        in_data = np.append(in_data, df_in, axis=1)\n",
    "        out_data = np.append(out_data, df_out, axis=1)\n",
    "    for i  in range(51,590):\n",
    "        df_in = pd.read_csv('cmu_us_'+ name_indata +'_arctic/wav/mfcc/arctic_a00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_in = df_in.values\n",
    "        df_out = pd.read_csv('cmu_us_'+ name_outdata +'_arctic/wav/mfcc/arctic_a00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_out = df_out.values\n",
    "        df_in,df_out = dtw(df_in,df_out)\n",
    "        in_data = np.append(in_data, df_in, axis=1)\n",
    "        out_data = np.append(out_data, df_out, axis=1)\n",
    "    return (in_data, out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_testset(name_indata,name_outdata):\n",
    "    in_data = np.zeros((25,0))\n",
    "    out_data = np.zeros((25,0))\n",
    "    for i in range(1,50):\n",
    "        df_in = pd.read_csv('cmu_us_'+ name_indata +'_arctic/wavtest/mfcc/arctic_a00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_in = df_in.values\n",
    "        df_out = pd.read_csv('cmu_us_'+ name_outdata +'_arctic/wavtest/mfcc/arctic_a00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_out = df_out.values\n",
    "        in_data = np.append(in_data, df_in, axis=1)\n",
    "        out_data = np.append(out_data, df_out, axis=1)\n",
    "    return (in_data,out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'indata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d90d968534fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train and test set for different networks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_Train_12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_Train_12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'awb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bdl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_Test_12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_Test_12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_testset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'awb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'bdl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-dfb4ff79fd79>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(name_indata, name_outdata)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cmu_us_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mname_outdata\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_arctic/wav/mfcc/arctic_b00'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdf_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_in\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0min_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-80d5ec1e4e1b>\u001b[0m in \u001b[0;36mdtw\u001b[0;34m(df_in, df_out)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_in\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_in\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex_in\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mindex_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0min_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'indata' is not defined"
     ]
    }
   ],
   "source": [
    "#train and test set for different networks\n",
    "\n",
    "X_Train_12,Y_Train_12 = load_data('awb','bdl')\n",
    "X_Test_12,Y_Test_12 = load_testset('awb','bdl')\n",
    "\n",
    "X_Train_13,Y_Train_13 = load_data('awb','ksp')\n",
    "X_Test_13,Y_Test_13 = load_testset('awb','ksp')\n",
    "\n",
    "X_Train_23,Y_Train_23 = load_data('bdl','ksp')\n",
    "X_Test_23,Y_Test_23 = load_testset('bdl','ksp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "##remember to add dropout and batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,input_shape=(25,None),use_bias=False))\n",
    "model.add(BatchNormalization()) #not quite sure on batch Norm params\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(100),use_bias=False)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(25),activation = 'tanh',use_bias=False)  ##output layer, does it need an activation?\n",
    "model.compile(loss='mean_sqaured_error',optimizers='Adam',metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,patience=5, min_lr=0.001,verbose = 1)\n",
    "model.fit(X_Train_12,Y_Train_12,batch_size=16*1120,epochs=5,verbose=1,validation_split=0.0,shuffle=True,callbacks=[reduce_lr])\n",
    "#batch_size is natch_size*no.of frames per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_Test_12,Y_Test_12,batch_size=8*1120,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
