{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from fastdtw import fastdtw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from librosa import display\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw(df_in,df_out):\n",
    "    in_data = np.zeros((25,0))\n",
    "    out_data = np.zeros((25,0))\n",
    "    distance, path = fastdtw(df_in.T,df_out.T)\n",
    "    for i in range(1,len(path)):\n",
    "        index_in, index_out = path[i]\n",
    "        a = df_in[:,index_in:index_in+1]\n",
    "        b = df_out[:,index_out:index_out+1]\n",
    "        in_data = np.append(in_data, a, axis = 1)\n",
    "        out_data = np.append(out_data, b, axis = 1)\n",
    "    return (out_data, in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(name_indata,name_outdata):\n",
    "    in_data = np.zeros((25,0))\n",
    "    out_data = np.zeros((25,0))\n",
    "    for i in range(1,540):\n",
    "        df_in = pd.read_csv('cmu_us_'+ name_indata +'_arctic/wav/mfcc/arctic_b00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_in = df_in.values\n",
    "        df_out = pd.read_csv('cmu_us_'+ name_outdata +'_arctic/wav/mfcc/arctic_b00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_out = df_out.values\n",
    "        df_in,df_out = dtw(df_in,df_out)\n",
    "        in_data = np.append(in_data, df_in, axis=1)\n",
    "        out_data = np.append(out_data, df_out, axis=1)\n",
    "    #for i  in range(51,590):\n",
    "        #df_in = pd.read_csv('cmu_us_'+ name_indata +'_arctic/wav/mfcc/arctic_a00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        #df_in = df_in.values\n",
    "        #df_out = pd.read_csv('cmu_us_'+ name_outdata +'_arctic/wav/mfcc/arctic_a00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        #df_out = df_out.values\n",
    "        #df_in,df_out = dtw(df_in,df_out)\n",
    "        #in_data = np.append(in_data, df_in, axis=1)\n",
    "        #out_data = np.append(out_data, df_out, axis=1)\n",
    "    return (in_data, out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_testset(name_indata,name_outdata):\n",
    "    in_data = np.zeros((25,0))\n",
    "    out_data = np.zeros((25,0))\n",
    "    for i in range(1,50):\n",
    "        df_in = pd.read_csv('cmu_us_'+ name_indata +'_arctic/wavtest/mfcc/arctic_a00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_in = df_in.values\n",
    "        df_out = pd.read_csv('cmu_us_'+ name_outdata +'_arctic/wavtest/mfcc/arctic_a00' + str(i) + '.csv',header=None,index_col=None)\n",
    "        df_out = df_out.values\n",
    "        in_data = np.append(in_data, df_in, axis=1)\n",
    "        out_data = np.append(out_data, df_out, axis=1)\n",
    "    return (in_data,out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and test set for different networks\n",
    "\n",
    "X_Train_12,Y_Train_12 = load_data('awb','bdl')\n",
    "X_Test_12,Y_Test_12 = load_testset('awb','bdl')\n",
    "\n",
    "#X_Train_13,Y_Train_13 = load_data('awb','ksp')\n",
    "#X_Test_13,Y_Test_13 = load_testset('awb','ksp')\n",
    "#X_Train_23,Y_Train_23 = load_data('bdl','ksp')\n",
    "#X_Test_23,Y_Test_23 = load_testset('bdl','ksp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "##remember to add dropout and batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100,input_shape=(25,None),use_bias=False))\n",
    "model.add(BatchNormalization()) #not quite sure on batch Norm params\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(100),use_bias=False)\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(25),activation = 'tanh',use_bias=False)  ##output layer, does it need an activation?\n",
    "model.compile(loss='mean_sqaured_error',optimizers='Adam',metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,patience=5, min_lr=0.001,verbose = 1)\n",
    "model.fit(X_Train_12,Y_Train_12,batch_size=16*1120,epochs=5,verbose=1,validation_split=0.0,shuffle=True,callbacks=[reduce_lr])\n",
    "#batch_size is natch_size*no.of frames per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_Test_12,Y_Test_12,batch_size=8*1120,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
